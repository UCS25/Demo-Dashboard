{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99937f0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c73b2fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "appointments.csv\n",
      "  Columns: ['Appointment ID', 'Name', 'Phone Number', 'Service Booked', 'Preferred Employee', 'Appointment Date', 'Time Slot', 'Duration', 'Status', 'Source']\n",
      "  First row: {'Appointment ID': 'APT1000', 'Name': 'Divya Rao', 'Phone Number': 918221053161, 'Service Booked': 'Facial', 'Preferred Employee': 'Kavita', 'Appointment Date': '2025-11-06', 'Time Slot': '17:30', 'Duration': 90, 'Status': 'Cancelled', 'Source': 'Website'}\n",
      "================================================================================\n",
      "attendance.csv\n",
      "  Columns: ['Staff Name', 'Date', 'Status', 'Check In', 'Check Out']\n",
      "  First row: {'Staff Name': 'Priya Sharma', 'Date': '2025-09-05', 'Status': 'Present', 'Check In': '10:15', 'Check Out': '19:34'}\n",
      "================================================================================\n",
      "branches.csv\n",
      "  Columns: ['Branch ID', 'Branch Name', 'Location', 'Manager']\n",
      "  First row: {'Branch ID': 'BR001', 'Branch Name': 'Main Branch', 'Location': 'MG Road', 'Manager': 'Priya Sharma'}\n",
      "================================================================================\n",
      "employees.csv\n",
      "  Columns: ['Employee Name', 'Role', 'Available']\n",
      "  First row: {'Employee Name': 'Priya', 'Role': 'Senior Stylist', 'Available': True}\n",
      "================================================================================\n",
      "leave_records.csv\n",
      "  Columns: ['Leave ID', 'Staff Name', 'Leave Type', 'From Date', 'To Date', 'Status', 'Remarks']\n",
      "  First row: {'Leave ID': 'LV1000', 'Staff Name': 'Sneha Patel', 'Leave Type': 'Sick Leave', 'From Date': '2025-10-27', 'To Date': '2025-11-01', 'Status': 'Rejected', 'Remarks': nan}\n",
      "================================================================================\n",
      "product_data.csv\n",
      "  Columns: ['Timestamp', 'DateTime', 'Client Name', 'Client Number', 'Sold by', 'Product Name', 'Bill Amount', 'Payment Mode', 'Helper']\n",
      "  First row: {'Timestamp': '13/09/2025 21:14:14', 'DateTime': '13/09/2025 21:14:14', 'Client Name': 'Anjali Sharma', 'Client Number': '+91 0231429001', 'Sold by': 'Ritu', 'Product Name': 'Himalaya Neem Face Pack', 'Bill Amount': 893, 'Payment Mode': 'Cash', 'Helper': 'Helper2'}\n",
      "================================================================================\n",
      "service_data.csv\n",
      "  Columns: ['Bill Date & Time', 'Timestamp', 'Name', 'Phone Number', 'Waxing', 'Facial', 'De-tan', 'Pedicure', 'Manicure', 'Bleaching', 'Wash', 'Massage', 'Threading', 'Hair Cut', 'Miscellaneous', 'Bill Amount', 'Service done by', 'Payment Mode', 'Helper for S', 'Bill Date', 'week', 'Name of the day']\n",
      "  First row: {'Bill Date & Time': '17/11/2025 22:08:14', 'Timestamp': '17/11/2025 22:08:14', 'Name': 'Nisha Verma', 'Phone Number': '+91 4332181960', 'Waxing': False, 'Facial': True, 'De-tan': False, 'Pedicure': False, 'Manicure': False, 'Bleaching': False, 'Wash': False, 'Massage': False, 'Threading': False, 'Hair Cut': False, 'Miscellaneous': nan, 'Bill Amount': 423, 'Service done by': 'Sneha', 'Payment Mode': 'Cash', 'Helper for S': 'Helper2', 'Bill Date': '17/11/2025', 'week': 47, 'Name of the day': 'Monday'}\n",
      "================================================================================\n",
      "services.csv\n",
      "  Columns: ['Service Name', 'Duration', 'Price']\n",
      "  First row: {'Service Name': 'Waxing', 'Duration': 45, 'Price': 500}\n",
      "================================================================================\n",
      "staff.csv\n",
      "  Columns: ['Staff ID', 'Name', 'Role', 'Phone', 'Email', 'Joining Date', 'Status', 'Salary', 'Branch']\n",
      "  First row: {'Staff ID': 'STF001', 'Name': 'Priya Sharma', 'Role': 'Senior Stylist', 'Phone': 919876543210, 'Email': 'priya@nat.com', 'Joining Date': '2022-01-15', 'Status': 'Active', 'Salary': 35000, 'Branch': 'Main Branch'}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "DATA_DIR = Path(\"data\")\n",
    "\n",
    "def summarize_df(df):\n",
    "    if df is None or df.empty:\n",
    "        return {\"columns\": list(df.columns) if df is not None else [], \"first_row\": None}\n",
    "    return {\"columns\": df.columns.tolist(), \"first_row\": df.iloc[0].to_dict()}\n",
    "\n",
    "def summarize_file(path: Path):\n",
    "    ext = path.suffix.lower()\n",
    "    summaries = []\n",
    "    try:\n",
    "        if ext in {\".csv\", \".txt\"}:\n",
    "            df = pd.read_csv(path, nrows=1)\n",
    "            summaries.append((path.name, None, summarize_df(df)))\n",
    "        elif ext == \".tsv\":\n",
    "            df = pd.read_csv(path, sep=\"\\t\", nrows=1)\n",
    "            summaries.append((path.name, None, summarize_df(df)))\n",
    "        elif ext in {\".xls\", \".xlsx\"}:\n",
    "            xls = pd.ExcelFile(path)\n",
    "            for sheet in xls.sheet_names:\n",
    "                df = pd.read_excel(path, sheet_name=sheet, nrows=1)\n",
    "                summaries.append((path.name, sheet, summarize_df(df)))\n",
    "        elif ext in {\".parquet\"}:\n",
    "            try:\n",
    "                df = pd.read_parquet(path)\n",
    "                summaries.append((path.name, None, summarize_df(df.head(1))))\n",
    "            except Exception:\n",
    "                summaries.append((path.name, None, {\"error\": \"failed to read parquet\"}))\n",
    "        elif ext in {\".json\"}:\n",
    "            # try JSON lines first\n",
    "            try:\n",
    "                df = pd.read_json(path, lines=True)\n",
    "                summaries.append((path.name, None, summarize_df(df.head(1))))\n",
    "            except ValueError:\n",
    "                try:\n",
    "                    df = pd.read_json(path)\n",
    "                    summaries.append((path.name, None, summarize_df(df.head(1))))\n",
    "                except Exception:\n",
    "                    # fallback: try to load and inspect top-level structure\n",
    "                    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "                        obj = json.load(f)\n",
    "                    if isinstance(obj, list) and obj:\n",
    "                        summaries.append((path.name, None, {\"columns\": list(obj[0].keys()) if isinstance(obj[0], dict) else [], \"first_row\": obj[0]}))\n",
    "                    else:\n",
    "                        summaries.append((path.name, None, {\"info\": f\"json top-level type: {type(obj).__name__}\"}))\n",
    "        elif ext in {\".feather\"}:\n",
    "            df = pd.read_feather(path)\n",
    "            summaries.append((path.name, None, summarize_df(df.head(1))))\n",
    "        else:\n",
    "            # generic attempt: try read_csv for delimited files\n",
    "            try:\n",
    "                df = pd.read_csv(path, nrows=1)\n",
    "                summaries.append((path.name, None, summarize_df(df)))\n",
    "            except Exception:\n",
    "                summaries.append((path.name, None, {\"info\": f\"unsupported or unreadable file type: {ext}\"}))\n",
    "    except Exception as e:\n",
    "        summaries.append((path.name, None, {\"error\": str(e)}))\n",
    "    return summaries\n",
    "\n",
    "results = []\n",
    "if not DATA_DIR.exists() or not DATA_DIR.is_dir():\n",
    "    print(f\"Directory not found: {DATA_DIR}\")\n",
    "else:\n",
    "    for p in sorted(DATA_DIR.iterdir()):\n",
    "        if p.is_file():\n",
    "            results.extend(summarize_file(p))\n",
    "\n",
    "# Print concise summary\n",
    "for fname, sheet, summary in results:\n",
    "    header = f\"{fname}\" + (f\" (sheet: {sheet})\" if sheet else \"\")\n",
    "    print(\"=\" * 80)\n",
    "    print(header)\n",
    "    if \"error\" in summary:\n",
    "        print(\"  Error:\", summary[\"error\"])\n",
    "        continue\n",
    "    if \"info\" in summary:\n",
    "        print(\"  Info:\", summary[\"info\"])\n",
    "        continue\n",
    "    print(\"  Columns:\", summary[\"columns\"])\n",
    "    print(\"  First row:\", summary[\"first_row\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21caa82d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
